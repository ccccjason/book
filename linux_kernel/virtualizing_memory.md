# Virtualizing Memory







對於特定的CPU，比如x86，保護模式下是不能繞過MMU的，這是硬件限制（其它架構CPU另說）。
內核地址也不例外。

只是它的映射關係是可以【固定、可計算、可預期的】——不像用戶態的地址，不經過內核查一次頁表，沒辦法知道main導致加載到那個物理地址。

這個固定映射關係的好處，給定虛擬地址，可以不經過頁表，就能【計算出】物理地址。
注意是計算出，真正訪問的時候還是要經過MMU/頁表。

什麼時候需要計算出物理地址呢？
比如網卡驅動做DMA，分配一段內核空間（kmalloc返回虛擬地址vp），這個地址要提交給硬件（寫某個控制寄存器），
但是硬件只知道物理地址，需要把vp轉換為物理地址（減少PAGE_OFFSET），再寫到寄存器裡。

如果不是直接映射，那好吧，就得把vp分成10-12-12幾段（假設32位3級頁表），
從cr3開始，一級一級的查下去，才能知道vp對應的物理內存。


“MMU 的page table”這個說法有點彆扭。Page table放在內存裡，但它不屬於MMU硬件單元。
MMU通過訪問內存裡的page table來完成地址映射，當然，為了加快速度，MMU內部有各種cache，最有名的就是TLB


CPU的角度看，page table的入口是cr3，任何時刻只有一份頁面在生效。
但是每個進程都有自己的頁表，同樣的虛地址映射不同的物理地址；當任務切換的時候，一個重要的操作就是更新cr3的內容。

舉個極為簡化的例子，假設系統中有兩個進程A，B。A的頁目錄佔用頁框#1，B的頁目錄佔用頁框#2（頁目錄是第一級索引），兩者佔用不同的物理地址。
當A運行的時候，cr3指向頁框#1，當B運行的時候，cr3切換到頁框#2。

在10-10-12的兩級分頁模式下，頁目錄由va的最高10位索引，共2^10=1k個條目，每個條目4byte（映射2^22=4M的地址空間），正好佔用1k*4=4kbyte=1page。
linux按照3G/1G的方式劃分，也就是說，頁目錄的前3/4的條目，索引3G的用戶空間，後面1/4的條目，索引1G的內核空間。

"所有進程共享內核空間"的含義，是指對進程A/B的頁目錄（即頁框#1/#2），它們後1/4的條目內容是幾乎相同的，指向同樣的1G/4k/1k=256個page table（排除高端映射的部分）。
